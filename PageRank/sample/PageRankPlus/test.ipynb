{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# @Time： 4/9/21 9:07 AM\n",
    "# @Author: dyf-2316\n",
    "# @FileName: PageRank.py\n",
    "# @Software: PyCharm\n",
    "# @Project: PageRank\n",
    "# @Description:\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from functools import wraps\n",
    "from math import log\n",
    "\n",
    "# import pyximport\n",
    "# pyximport.install(language_level=3)\n",
    "# from pagerank_extension.extensions import update_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "\n",
    "\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "@cython.wraparound(False)  # turn off negative index wrapping for entire function\n",
    "def update_rank(dict out_links,np.ndarray[double,ndim=1] new_rank,np.ndarray[double,ndim=1] old_rank,double alpha):\n",
    "    cdef int node, degree, link\n",
    "    for node, [degree, links] in out_links.items():\n",
    "        for link in links:\n",
    "            new_rank[link - 1] += alpha * old_rank[node - 1] / degree\n",
    "    return new_rank"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pagerank_extension.extensions'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-11-929e453d763d>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     81\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     82\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 83\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mpagerank_extension\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextensions\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mupdate_rank\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     84\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pagerank_extension.extensions'"
     ]
    }
   ],
   "source": [
    "def timethis(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        r = func(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        print('{}.{} : elapse time {}'.format(func.__module__, func.__name__, end - start))\n",
    "        return r\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class GammaCompressor:\n",
    "    @staticmethod\n",
    "    def int_to_bin(int_in):\n",
    "        \"\"\"\n",
    "\n",
    "        :param int_in:\n",
    "        :return:\n",
    "            ret: str\n",
    "\n",
    "        \"\"\"\n",
    "        if int_in == 0:\n",
    "            return '0'\n",
    "        # 去除第一个位，因此是print(bin(5)) 0b101\n",
    "        ret = '1' * int(log(int_in, 2)) + '0' + bin(int_in)[3:]\n",
    "        return ret\n",
    "\n",
    "    @staticmethod\n",
    "    def encode(postings_list):\n",
    "        \"\"\"Encodes `postings_list`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        postings_list: List[int]\n",
    "            The postings list to be encoded\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bytes:\n",
    "            bytes reprsentation of the compressed postings list\n",
    "        \"\"\"\n",
    "        ### Begin your code\n",
    "        encoded_postings_list = ''\n",
    "        for i in range(0, len(postings_list)):\n",
    "            # 加一是为了处理0和1的情况\n",
    "            encoded_postings_list += GammaCompressor.int_to_bin(postings_list[i] + 1)\n",
    "        return encoded_postings_list.encode()\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(encoded_postings):\n",
    "        \"\"\"Decodes a byte representation of compressed postings list\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        encoded_postings: bytes\n",
    "            Bytes representation as produced by `CompressedPostings.encode`\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List[int]\n",
    "            Decoded postings list (each posting is a docId)\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        i = 0\n",
    "        byteslen = len(encoded_postings)\n",
    "        encoded_postings = encoded_postings.decode()\n",
    "        while True:\n",
    "            length = 0\n",
    "            while encoded_postings[i] != '0':\n",
    "                i += 1\n",
    "                length += 1\n",
    "            i += 1\n",
    "            val = int('1' + encoded_postings[i:i + length], 2) - 1\n",
    "            res.append(val)\n",
    "            i = i + length\n",
    "            if i >= byteslen:\n",
    "                return res\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from pagerank_extension.extensions import update_rank\n",
    "\n",
    "\n",
    "class PageRank:\n",
    "    def __init__(self,\n",
    "                 beta=0.85,\n",
    "                 max_iter=100,\n",
    "                 tol=1.0e-16,\n",
    "                 block_num=0,\n",
    "                 data_path='WikiData.txt',\n",
    "                 result_path='result.txt',\n",
    "                 report_top_num=100):\n",
    "        self.beta = beta\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.N = 0\n",
    "        self.out_links = {}\n",
    "        self.block_num = block_num\n",
    "        self.blocks = []\n",
    "        self.out_degree = {}\n",
    "        self.data_path = data_path\n",
    "        self.result_path = result_path\n",
    "        self.report_top_num = report_top_num\n",
    "        self.new_rank = None\n",
    "        self.old_rank = None\n",
    "\n",
    "    def run_workflow(self):\n",
    "        self.load_and_process_data()\n",
    "        start = time.time()\n",
    "\n",
    "        print('Start paging rank')\n",
    "        start_page_rank = time.time()\n",
    "        self.page_rank()\n",
    "        end_page_rank = time.time()\n",
    "        print('Running time: %s Seconds' % (end_page_rank - start_page_rank))\n",
    "\n",
    "        self.save_result()\n",
    "        end = time.time()\n",
    "        print('Total running time: %s Seconds' % (end - start))\n",
    "\n",
    "        statistics = {\n",
    "            'Block Num.': self.block_num,\n",
    "            'Alg. time': end_page_rank - start_page_rank,\n",
    "            'Total Time': end - start\n",
    "        }\n",
    "        return statistics\n",
    "\n",
    "    def load_and_process_data(self):\n",
    "        if self.block_num == 1:\n",
    "            data = np.loadtxt(self.data_path, dtype=int)\n",
    "            for edge in data:\n",
    "                self.out_links.setdefault(edge[0], [0, []])\n",
    "                self.out_links[edge[0]][1].append(edge[1])\n",
    "                self.out_links[edge[0]][0] += 1\n",
    "\n",
    "                # 统计节点\n",
    "                if edge[0] > self.N:\n",
    "                    self.N = edge[0]\n",
    "                if edge[1] > self.N:\n",
    "                    self.N = edge[1]\n",
    "\n",
    "        else:\n",
    "            with open(self.data_path, 'r') as f:\n",
    "                # 统计所有的节点个数\n",
    "                edge = f.readline()\n",
    "                while edge:\n",
    "                    edge = np.array(edge.split()).astype(int)\n",
    "                    if int(edge[0]) > self.N:\n",
    "                        self.N = edge[0]\n",
    "                    if int(edge[1]) > self.N:\n",
    "                        self.N = edge[1]\n",
    "                    edge = f.readline()\n",
    "                # 为节点分块并将块存储到磁盘\n",
    "                step = int(np.ceil(self.N / self.block_num))\n",
    "                for block_id, start_node in enumerate(range(1, self.N + 1, step)):\n",
    "                    f.seek(0)\n",
    "                    out_links = {}\n",
    "                    edge = f.readline()\n",
    "                    while edge:\n",
    "                        edge = np.array(edge.split()).astype(int)\n",
    "                        if start_node <= edge[1] < start_node + step:\n",
    "                            out_links.setdefault(edge[0], [0,[]])\n",
    "                            out_links[edge[0]][1].append(edge[1])\n",
    "                            self.out_degree.setdefault(edge[0], 0)\n",
    "                            self.out_degree[edge[0]] += 1\n",
    "                        edge = f.readline()\n",
    "                    self.blocks.append('block' + str(block_id + 1) + '.npy')\n",
    "                    for key in out_links.keys():\n",
    "                        out_links[key][0]=self.out_degree[key]\n",
    "                    np.save(self.blocks[-1], out_links)\n",
    "\n",
    "    def page_rank(self):\n",
    "        self.load_and_process_data()\n",
    "        self.old_rank = np.full(self.N, 1 / self.N, dtype=float)\n",
    "        for i in range(self.max_iter):\n",
    "            self.new_rank = np.zeros(self.N, dtype=float)\n",
    "            if self.block_num == 1:\n",
    "                # for node, [degree, links] in self.out_links.items():\n",
    "                #     for link in links:\n",
    "                #         self.new_rank[link - 1] += self.beta * self.old_rank[node - 1] / degree\n",
    "                self.new_rank = update_rank(self.out_links, self.new_rank, self.old_rank, self.beta)\n",
    "            else:\n",
    "                for block_path in self.blocks:\n",
    "                    block = np.load(block_path, allow_pickle=True).item()\n",
    "                    self.new_rank=update_rank(block, self.new_rank, self.old_rank,self.beta)\n",
    "            self.new_rank += (1 - np.sum(self.new_rank)) / self.N\n",
    "            convergence = np.round(np.sum(np.fabs(self.old_rank - self.new_rank)),2)\n",
    "            print('iteration times:', i + 1, ', convergence:', convergence)\n",
    "            if convergence < self.tol:\n",
    "                break\n",
    "            self.old_rank = self.new_rank\n",
    "\n",
    "    def save_result(self):\n",
    "        result = sorted(zip(self.new_rank, range(1, self.N + 1)), reverse=True)\n",
    "        with open(self.result_path, 'w') as f:\n",
    "            for i in range(self.report_top_num):\n",
    "                f.write(\n",
    "                    str(result[i][1]) + ' ' + str(result[i][0]) + '\\n'\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PageRankPlus:\n",
    "    def __init__(self, alpha=0.85, max_iter=100, tol=2.0e-16, isCompressed=True):\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.N = 0\n",
    "        self.new_rank = None\n",
    "        self.old_rank = None\n",
    "        self.out_links = {}  # node: [degree, links]\n",
    "        self.block_num = 0\n",
    "        self.blocks = []\n",
    "        self.out_degree = {}\n",
    "        self.isCompressed = isCompressed\n",
    "\n",
    "    def load_data(self, data_path, block_num=1, block_id=0, isCompressed=True):\n",
    "        '''\n",
    "        加载数据，可以从之前压缩的文件获取，也可以从原始文件获取\n",
    "        Parameters\n",
    "        ----------\n",
    "        block_num\n",
    "        data_path\n",
    "        isCompressed\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        '''\n",
    "        # 从压缩文件获取 [dst... src degree],每一行是一个src node\n",
    "        if isCompressed:\n",
    "            # 不分块处理\n",
    "            if block_num == 1:\n",
    "                # 通过节点id计算节点总数，包括孤立点\n",
    "                with open('compressed_' + data_path, 'rb') as fr:\n",
    "                    metalist = fr.readlines()\n",
    "                    for meta in metalist:\n",
    "                        m = GammaCompressor.decode(meta.strip())\n",
    "                        self.out_links.setdefault(m[-2], [0, []])\n",
    "                        self.out_links[m[-2]][1] = m[:-2]  # posting list\n",
    "                        self.out_links[m[-2]][0] = m[-1]  # degree\n",
    "\n",
    "            # 分块处理\n",
    "            else:\n",
    "                filename = 'compressed_block' + str(block_id + 1) + '_' + data_path\n",
    "                with open(filename, 'rb') as fr:\n",
    "                    metalist = fr.readlines()\n",
    "                    for meta in metalist:\n",
    "                        m = GammaCompressor.decode(meta.strip())\n",
    "                        self.out_links.setdefault(m[-2], [0, []])\n",
    "                        self.out_links[m[-2]][1] = m[:-2]  # posting list\n",
    "                        self.out_links[m[-2]][0] = m[-1]  # degree\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            # 不分块处理\n",
    "            if block_num == 1:\n",
    "                data = np.loadtxt(data_path, dtype=int)\n",
    "                for edge in data:\n",
    "                    self.out_links.setdefault(edge[0], [0, []])\n",
    "                    self.out_links[edge[0]][1].append(edge[1])\n",
    "                    self.out_links[edge[0]][0] += 1\n",
    "                    if edge[0] > self.N:\n",
    "                        self.N = edge[0]\n",
    "                    if edge[1] > self.N:\n",
    "                        self.N = edge[1]\n",
    "            # 分块处理\n",
    "            else:\n",
    "                filename = str(block_id + 1) + '.npy'\n",
    "                # fixme\n",
    "                #   np.load\n",
    "                with open(filename, 'rb') as fr:\n",
    "                    metalist = fr.readlines()\n",
    "                    for meta in metalist:\n",
    "                        m = GammaCompressor.decode(meta.strip())\n",
    "                        self.out_links.setdefault(m[-2], [0, []])\n",
    "                        self.out_links[m[-2]][1] = m[:-2]  # posting list\n",
    "                        self.out_links[m[-2]][0] = m[-1]  # degree\n",
    "\n",
    "\n",
    "                with open(data_path, 'r') as f:\n",
    "                    # 统计所有的节点个数\n",
    "                    edge = f.readline()\n",
    "                    while edge:\n",
    "                        edge = np.array(edge.split()).astype(int)\n",
    "                        if int(edge[0]) > self.N:\n",
    "                            self.N = edge[0]\n",
    "                        if int(edge[1]) > self.N:\n",
    "                            self.N = edge[1]\n",
    "                        edge = f.readline()\n",
    "                    # 为节点分块并将块存储到磁盘\n",
    "                    step = int(self.N / block_num)\n",
    "                    for block_id, start_node in enumerate(range(1, self.N + 1, step)):\n",
    "                        f.seek(0)\n",
    "                        out_links = {}\n",
    "                        edge = f.readline()\n",
    "                        while edge:\n",
    "                            edge = np.array(edge.split()).astype(int)\n",
    "                            if start_node <= edge[1] < start_node + step:\n",
    "                                out_links.setdefault(edge[0], [])\n",
    "                                out_links[edge[0]].append(edge[1])\n",
    "                                self.out_degree.setdefault(edge[0], 0)\n",
    "                                self.out_degree[edge[0]] += 1\n",
    "                            edge = f.readline()\n",
    "                        self.blocks.append('block' + str(block_id + 1) + '.npy')\n",
    "                        np.save(self.blocks[-1], out_links)\n",
    "\n",
    "    # @timethis\n",
    "    def preprocess_data(self, data_path, block_num=1):\n",
    "        '''\n",
    "        input: original nodes data\n",
    "        output: write into file with encoded data presented as bytes, [dst... src degree ]形式\n",
    "\n",
    "        根据是否分块，将文件以不同的形式写入同一个文件（如果分块即用换行来表示）\n",
    "        且文件不需要全部立即读入内存，只需要留存着FileDescriptor就可以继续读文件，实现分块\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_path\n",
    "        block_num\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        '''\n",
    "\n",
    "        with open(data_path, 'r') as fr:\n",
    "\n",
    "            if block_num == 1:\n",
    "                with open('compressed_' + data_path, 'wb') as fw:\n",
    "                    data = np.loadtxt(data_path, dtype=int)  # n*2的一个矩阵\n",
    "                    for edge in data:\n",
    "                        # 如果没有这个节点，那么创建，并且以格式 [dst... src degree ] 展现\n",
    "                        self.out_links.setdefault(edge[0], [0, []])\n",
    "                        self.out_links[edge[0]][1].append(edge[1])\n",
    "                        self.out_links[edge[0]][0] += 1\n",
    "                    for src in self.out_links.keys():\n",
    "                        # 将src和degree加入list，并写入一行\n",
    "                        temp = self.out_links.get(src)[1]  # [dst... src degree ]\n",
    "                        temp.extend([src, self.out_links.get(src)[0]])\n",
    "                        fw.write(GammaCompressor.encode(temp))\n",
    "                        fw.write('\\n'.encode())\n",
    "            else:\n",
    "                # 统计所有的节点个数\n",
    "                if self.N == 0:\n",
    "                    edge = fr.readline()\n",
    "                    while edge:\n",
    "                        edge = np.array(edge.split()).astype(int)\n",
    "                        if int(edge[0]) > self.N:\n",
    "                            self.N = edge[0]\n",
    "                        if int(edge[1]) > self.N:\n",
    "                            self.N = edge[1]\n",
    "                        edge = fr.readline()\n",
    "                    # 为节点分块并将块存储到磁盘\n",
    "                # note 根据节点id分块\n",
    "                step = int(self.N / block_num)\n",
    "                for block_id, start_node in enumerate(range(1, self.N + 1, step)):\n",
    "                    fr.seek(0)\n",
    "                    metadict = {}\n",
    "                    edge = fr.readline()\n",
    "                    # 扫描整个文件，并根据当前块存储相应数据\n",
    "                    while edge:\n",
    "                        edge = np.array(edge.split()).astype(int)\n",
    "                        if start_node <= edge[1] < start_node + step:\n",
    "                            metadict.setdefault(edge[0], [0, []])\n",
    "                            metadict[edge[0]][1].append(edge[1])\n",
    "                            metadict[edge[0]][0] += 1\n",
    "                        edge = fr.readline()\n",
    "                    filename = 'compressed_block' + str(block_id + 1) + '_' + data_path\n",
    "                    self.blocks.append(filename)\n",
    "                    with open(filename, 'wb') as fw:\n",
    "                        for meta in metadict.items():\n",
    "                            temp = meta[1][1]\n",
    "                            temp.extend([meta[0], meta[1][0]])\n",
    "                            fw.write(GammaCompressor.encode(temp))\n",
    "                            fw.write('\\n'.encode())\n",
    "\n",
    "    def initialize_rank(self, data_path):\n",
    "        with open(data_path, 'r') as fr:\n",
    "            # 通过读取源文件统计所有的节点个数\n",
    "            if self.N == 0:\n",
    "                edge = fr.readline()\n",
    "                while edge:\n",
    "                    edge = np.array(edge.split()).astype(int)\n",
    "                    if int(edge[0]) > self.N:\n",
    "                        self.N = edge[0]\n",
    "                    if int(edge[1]) > self.N:\n",
    "                        self.N = edge[1]\n",
    "                    edge = fr.readline()\n",
    "        return np.full(self.N, 1 / self.N, dtype=float)\n",
    "\n",
    "    def page_rank(self, data_path, block_num):\n",
    "        old_rank = self.initialize_rank(data_path)\n",
    "        for i in range(self.max_iter):\n",
    "            new_rank = np.zeros(self.N, dtype=float)\n",
    "            if block_num == 1:\n",
    "                self.load_data(data_path, block_num)\n",
    "                # for node, [degree, links] in self.out_links.items():\n",
    "                #     for link in links:\n",
    "                #         new_rank[link - 1] += self.alpha * old_rank[node - 1] / degree\n",
    "\n",
    "                # use cython code\n",
    "                new_rank = update_rank(self.out_links, new_rank, old_rank, self.alpha)\n",
    "            else:\n",
    "                for block_id in range(block_num + 1):\n",
    "                    self.load_data(data_path, block_num=block_num, block_id=block_id, isCompressed=self.isCompressed)\n",
    "                    print(self.out_links)\n",
    "                    # for node, [degree, links] in self.out_links.items():\n",
    "                    #     for link in links:\n",
    "                    #         new_rank[link - 1] += self.alpha * old_rank[node - 1] / degree\n",
    "\n",
    "                    # use cython code\n",
    "                    new_rank=update_rank(self.out_links,new_rank,old_rank,self.alpha)\n",
    "\n",
    "            new_rank += (1 - new_rank.sum()) / self.N  # temp\n",
    "            print('iter {}, {}'.format(i, round(new_rank.sum(), 2)))\n",
    "\n",
    "            convergence = sum(abs(old_rank - new_rank))\n",
    "            if convergence < self.tol:\n",
    "                self.new_rank = new_rank\n",
    "                return\n",
    "            old_rank = new_rank\n",
    "        print('iteration exceed')\n",
    "        self.new_rank = old_rank\n",
    "        self.new_rank /= self.new_rank.sum()\n",
    "\n",
    "    def save_result(self, result_path):\n",
    "        result = sorted(zip(self.new_rank, range(1, self.N + 1)), reverse=True)\n",
    "        with open(result_path, 'w') as f:\n",
    "            for i in range(100):\n",
    "                f.write('[' + str(result[i][1]) + '] [' + str(result[i][0]) + ']\\n')\n",
    "        # if self.block_num > 1:\n",
    "        #     for block_path in self.blocks:\n",
    "        #         os.remove(block_path)\n",
    "\n",
    "    def exec(self, block_num: int, data_path, result_path):\n",
    "        start = time.perf_counter()\n",
    "        self.block_num = block_num\n",
    "\n",
    "        print('Start paging rank')\n",
    "        start_page_rank = time.perf_counter()\n",
    "        self.page_rank(data_path, block_num)\n",
    "        end_page_rank = time.perf_counter()\n",
    "        print('Running time: %s Seconds' % (end_page_rank - start_page_rank))\n",
    "\n",
    "        self.save_result(result_path)\n",
    "        end = time.perf_counter()\n",
    "        print('Total running time: %s Seconds' % (end - start))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PageRank' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-12-6e26745e8c65>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mblock_num\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m5\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m pr = PageRank(\n\u001B[0m\u001B[0;32m      3\u001B[0m     \u001B[0mbeta\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.85\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mmax_iter\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mtol\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1.0e-16\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'PageRank' is not defined"
     ]
    }
   ],
   "source": [
    "block_num = 5\n",
    "pr = PageRank(\n",
    "    beta=0.85,\n",
    "    max_iter=100,\n",
    "    tol=1.0e-16,\n",
    "    block_num=block_num,\n",
    "    data_path='WikiData.txt',\n",
    "    result_path='result.txt',\n",
    "    report_top_num=100\n",
    ")\n",
    "pr.run_workflow()\n",
    "\n",
    "\n",
    "x=np.arange(10)\n",
    "x+=1\n",
    "y=[]\n",
    "for block_num in x:\n",
    "    test = PageRank()\n",
    "    # test.compress_data(data_path, block_num)\n",
    "    y.append(test.exec(block_num=block_num, data_path=data_path, result_path=result_path)['Alg. time'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x,y,'r-')\n",
    "plt.xlabel('Block Numbers')\n",
    "plt.ylabel('RunTime(s)')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}